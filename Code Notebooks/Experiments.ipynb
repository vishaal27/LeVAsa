{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiments_Reproducibility",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edfe822f9dbd4fd4b142b534942d5ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32e53e5d74d84812bb7d2dffafeb660d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07be2e757d0f4bf8b90e33b1d175c971",
              "IPY_MODEL_7a22836c82eb4823a9eeb2b6e7b1c00c"
            ]
          }
        },
        "32e53e5d74d84812bb7d2dffafeb660d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07be2e757d0f4bf8b90e33b1d175c971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f6f6acfbed8945a28da71f9d5496a0d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_227c8725c6644bc5ba80cc4299b45ea1"
          }
        },
        "7a22836c82eb4823a9eeb2b6e7b1c00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19bf28785e2949639c2009a28d44971c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/? [13:37&lt;00:00,  1.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7e292c1fdee49bd8f2fab4879b647eb"
          }
        },
        "f6f6acfbed8945a28da71f9d5496a0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "227c8725c6644bc5ba80cc4299b45ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19bf28785e2949639c2009a28d44971c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7e292c1fdee49bd8f2fab4879b647eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33f48baa932749fa8c659f0e8699d56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fbd4d05b7d04591b3089a675128ebb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e4aca49830b4ba48c179fb7cd1b38c4",
              "IPY_MODEL_78b9e36ed9104cd8972bbedcc236f8ce"
            ]
          }
        },
        "8fbd4d05b7d04591b3089a675128ebb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e4aca49830b4ba48c179fb7cd1b38c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a74acad2586342b1ba276ce793db06d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0adffb90dc344525924559048be6e539"
          }
        },
        "78b9e36ed9104cd8972bbedcc236f8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e32ab0d15db44e39db5974be1283748",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/? [11:33&lt;00:00,  1.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f8970724df94dec8b988efcf8ea0cf2"
          }
        },
        "a74acad2586342b1ba276ce793db06d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0adffb90dc344525924559048be6e539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e32ab0d15db44e39db5974be1283748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f8970724df94dec8b988efcf8ea0cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RzLHp-j0kvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "11d0d584-dbb2-4eb1-d0f1-5326f94fe1ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk5-6bvP5akf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn import manifold\n",
        "\n",
        "import random\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebVY8fFxkH8n",
        "colab_type": "text"
      },
      "source": [
        "# **Table 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-FnpVYAlQO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2a80d21-e830-407c-badb-36c714dce9ff"
      },
      "source": [
        "is_training = False\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcc6epatk6pX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ee01bf8-110a-4ba5-85ab-d99292ce655a"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\t\tdef __init__(self):\n",
        "\t\t\t\tsuper(Encoder, self).__init__()\n",
        "\t\t\t\tself.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.linear_mean_v = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_std_v = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_mean_a = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_std_a = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_mean_z = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_std_z = nn.Linear(in_features=128, out_features=32, bias=True)\t\t\t\t\n",
        "\t\t\t\tself.features = nn.Linear(in_features=4608, out_features=512, bias=True)\n",
        "\t\t\t\tself.fc = nn.Linear(in_features=512, out_features=128)\n",
        "\t\t\t\tself.bn_1 = nn.BatchNorm2d(64)\n",
        "\t\t\t\tself.bn_2 = nn.BatchNorm2d(128)\n",
        "\t\t\t\tself.bn_3 = nn.BatchNorm2d(256)\n",
        "\t\t\t\tself.bn_4 = nn.BatchNorm2d(512)\n",
        "\t\t\t\tself.bn_5 = nn.BatchNorm1d(512)\n",
        "\t\t\t\tself.bn_6 = nn.BatchNorm1d(128)\n",
        "\t\t\t\tself.relu = nn.ReLU()\n",
        "\t\t\t\tself.elu = nn.ELU(0.1)\n",
        "\t\t\n",
        "\t\tdef reparameterize(self, mu, logvar):\n",
        "\t\t\t\tif is_training:\n",
        "\t\t\t\t\tstd = logvar.mul(0.5).exp_()\n",
        "\t\t\t\t\teps = torch.randn_like(std)\n",
        "\t\t\t\t\tif(torch.cuda.is_available()):\n",
        "\t\t\t\t\t\teps = eps.cuda()\n",
        "\t\t\t\t\treturn eps.mul(std).add_(mu)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\treturn mu\n",
        "\n",
        "\t\tdef forward(self, x):\n",
        "\t\t\tx = self.relu(self.bn_1(self.conv1(x)))\n",
        "\t\t\tx = self.relu(self.bn_2(self.conv2(x)))\n",
        "\t\t\tx = self.relu(self.bn_3(self.conv3(x)))\n",
        "\t\t\tx = self.relu(self.bn_4(self.conv4(x)))\n",
        "\t\t\tx = x.view(x.size(0), x.size(1)*x.size(2)*(x.size(3)))\n",
        "\t\t\t\n",
        "\t\t\tlatent_feats = self.relu(self.bn_6(self.fc(self.relu(self.bn_5(self.features(x))))))\n",
        "\t\t\tmu_v = self.linear_mean_v(latent_feats)\n",
        "\t\t\tlogvar_v = self.linear_std_v(latent_feats)\n",
        "\t\t\tmu_a = self.linear_mean_a(latent_feats)\n",
        "\t\t\tlogvar_a = self.linear_std_a(latent_feats)\n",
        "\t\t\tmu_z = self.linear_mean_z(latent_feats)\n",
        "\t\t\tlogvar_z = self.linear_std_z(latent_feats)\t \t \n",
        "\t\t\tz_v = self.reparameterize(mu_v, logvar_v)\n",
        "\t\t\tz_a = self.reparameterize(mu_a, logvar_a)\n",
        "\t\t\tz_z = self.reparameterize(mu_z, logvar_z)\t \t \n",
        "\t\t\treturn z_v, mu_v, logvar_v, z_a, mu_a, logvar_a, z_z, mu_z, logvar_z\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\t\tdef __init__(self):\n",
        "\t\t\t\tsuper(Decoder, self).__init__()\n",
        "\t\t\t\tself.inv_fc = nn.Linear(in_features=128, out_features=512, bias=True)\n",
        "\t\t\t\tself.features = nn.Linear(in_features=512, out_features=4608, bias=True)\n",
        "\t\t\t\tself.reconstruct = nn.Linear(in_features=96, out_features=128, bias=True)\n",
        "\t\t\t\tself.deconv_1 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.deconv_2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.deconv_3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.deconv_4 = nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4, stride=2, bias=True)\n",
        "\t\t\t\tself.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "\t\t\t\tself.bn_1 = nn.BatchNorm1d(num_features=512)\n",
        "\t\t\t\tself.bn_2 = nn.BatchNorm1d(num_features=4608)\n",
        "\t\t\t\tself.bn_3 = nn.BatchNorm2d(num_features=256)\n",
        "\t\t\t\tself.bn_4 = nn.BatchNorm2d(num_features=128)\n",
        "\t\t\t\tself.bn_5 = nn.BatchNorm2d(num_features=64)\n",
        "\t\t\t\tself.bn_6 = nn.BatchNorm2d(num_features=3)\n",
        "\n",
        "\t\t\t\tself.tanh = nn.Tanh()\n",
        "\t\t\t\tself.relu =nn.ReLU()\n",
        "\n",
        "\t\tdef forward(self, z_v, z_a, z_z):\n",
        "\t\t\tconcat = torch.cat([z_v, z_a], dim=1)\n",
        "\t\t\tconcat = torch.cat([concat, z_z], dim=1)\n",
        "\t\t\tlatent = self.relu(self.bn_1(self.inv_fc(self.relu(self.reconstruct(concat)))))\n",
        "\t\t\tlatent = self.relu(self.bn_2(self.features(latent)))\n",
        "\t\t\tx = latent.view(latent.size(0), 512, 3, 3)\n",
        "\t\t\tx = self.relu(self.bn_3(self.deconv_1(x)))\n",
        "\t\t\tx = self.relu(self.bn_4(self.deconv_2(x)))\n",
        "\t\t\tx = self.relu(self.bn_5(self.deconv_3(x)))\n",
        "\t\t\tx = self.relu(self.bn_6(self.deconv_4(x)))\n",
        "\t\t\treturn x\n",
        "\n",
        "enc = Encoder()\n",
        "enc.cuda()\n",
        "z_v,_,_, z_a, _, _, z_z, _, _ = enc.forward(torch.randn(10, 3, 64, 64).cuda())\n",
        "print('Latents:', z_v.shape, z_a.shape, z_z.shape)\n",
        "\n",
        "dec = Decoder()\n",
        "dec.cuda()\n",
        "i = dec.forward(z_v, z_a, z_z)\n",
        "print('Recons:', i.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latents: torch.Size([10, 32]) torch.Size([10, 32]) torch.Size([10, 32])\n",
            "Recons: torch.Size([10, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MNy_Ekbk0gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_loss(input1, target):\n",
        "\treturn torch.sum((input1 - target).pow(2)) / input1.data.nelement()\n",
        " \n",
        "def mae_loss(input1, target):\n",
        "\treturn abs(torch.sum((input1 - target).pow(1)) / input1.data.nelement())\n",
        "\n",
        "def weights_init(layer):\n",
        "\tif isinstance(layer, nn.Conv2d):\n",
        "\t\tlayer.weight.data.normal_(0.0, 0.05)\n",
        "\t\tlayer.bias.data.zero_()\n",
        "\telif isinstance(layer, nn.BatchNorm2d):\n",
        "\t\tlayer.weight.data.normal_(1.0, 0.02)\n",
        "\t\tlayer.bias.data.zero_()\n",
        "\telif isinstance(layer, nn.Linear):\n",
        "\t\tlayer.weight.data.normal_(0.0, 0.05)\n",
        "\t\tlayer.bias.data.zero_()\n",
        "\n",
        "\n",
        "def imshow_grid(images, shape=[2, 8], name='default', save=False):\n",
        "\t\"\"\"Plot images in a grid of a given shape.\"\"\"\n",
        "\tfig = plt.figure(1)\n",
        "\tgrid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n",
        "\n",
        "\tsize = shape[0] * shape[1]\n",
        "\tfor i in range(size):\n",
        "\t\tgrid[i].axis('off')\n",
        "\t\tgrid[i].imshow(images[i])  # The AxesGrid object work as a list of axes.\n",
        "\n",
        "\tif save:\n",
        "\t\tplt.savefig('reconstructed_images/' + str(name) + '.png')\n",
        "\t\tplt.clf()\n",
        "\telse:\n",
        "\t\tplt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc7xeuZtkugy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "json_file = '/content/drive/My Drive/LeVAsa_CODS_COMAD/jsons/IMFDB_va.json'\n",
        "\n",
        "with open(json_file) as f:\n",
        "  va_dictionary = json.load(f)\n",
        "\n",
        "import json\n",
        "\n",
        "json_file = '/content/drive/My Drive/LeVAsa_CODS_COMAD/jsons/IMFDB_labels.json'\n",
        "\n",
        "with open(json_file) as f:\n",
        "  label_dictionary = json.load(f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCpInDgrkmif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_mapping = ['ANGER', 'DISGUST', 'FEAR', 'HAPPINESS', 'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
        "\n",
        "class ImageFolderWithPathsIMFDB(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPathsIMFDB, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        # folder = path[-13:-10]\n",
        "        fil = path[path.rfind('/')+1:]\n",
        "        emotion = (emotion_mapping.index(label_dictionary[fil]),)\n",
        "        tuple_with_path = (original_tuple+(va_dictionary[fil],)+emotion)\n",
        "        return tuple_with_path"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNDLeRyuuxx1",
        "colab_type": "text"
      },
      "source": [
        "## **Vanilla**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUtWxR1fkLwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "edfe822f9dbd4fd4b142b534942d5ff2",
            "32e53e5d74d84812bb7d2dffafeb660d",
            "07be2e757d0f4bf8b90e33b1d175c971",
            "7a22836c82eb4823a9eeb2b6e7b1c00c",
            "f6f6acfbed8945a28da71f9d5496a0d2",
            "227c8725c6644bc5ba80cc4299b45ea1",
            "19bf28785e2949639c2009a28d44971c",
            "f7e292c1fdee49bd8f2fab4879b647eb"
          ]
        },
        "outputId": "b40e2223-7b3a-4590-b9f2-492b42b7f554"
      },
      "source": [
        "encoder = Encoder()\n",
        "encoder.apply(weights_init)\n",
        "encoder.load_state_dict(torch.load('/content/drive/My Drive/LeVAsa_CODS_COMAD/experiments/Table_1_continuous/Vanilla_VAE/encoder'))\n",
        "\n",
        "decoder = Decoder()\n",
        "decoder.apply(weights_init)\n",
        "decoder.load_state_dict(torch.load('/content/drive/My Drive/LeVAsa_CODS_COMAD/experiments/Table_1_continuous/Vanilla_VAE/decoder'))\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "print('Loading Dataset...')\n",
        "data_dir = '/content/drive/My Drive/LeVAsa_CODS_COMAD/final_images/'\n",
        "transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
        "dset = ImageFolderWithPathsIMFDB(data_dir, transform=transform)\n",
        "print(dset.imgs[:10])\n",
        "data_object = torch.utils.data.DataLoader(dset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "X1 = torch.zeros(batch_size, 3, 64, 64)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  encoder.cuda()\n",
        "  decoder.cuda()\n",
        "  X1 = X1.cuda()\n",
        "\n",
        "s_metric = 0\n",
        "s_m1 = 0\n",
        "s_m2 = 0\n",
        "s_m3 = 0\n",
        "s_m4 = 0\n",
        "s_m5 = 0\n",
        "s_m6 = 0\n",
        "\n",
        "a_metric = 0\n",
        "a_m1 = 0\n",
        "a_m2 = 0\n",
        "a_m3 = 0\n",
        "a_m4 = 0\n",
        "a_m5 = 0\n",
        "a_m6 = 0\n",
        "\n",
        "s_v_m = 0\n",
        "s_a_m = 0\n",
        "a_v_m = 0\n",
        "a_a_m = 0\n",
        "\n",
        "all_z_v = []\n",
        "all_z_a = []\n",
        "\n",
        "all_v_labels = []\n",
        "all_a_labels = []\n",
        "all_emotion_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for iteration, (data_, _, labels, emotions) in tqdm(enumerate(data_object)):\n",
        "      image_batch_1 = data_\n",
        "      X1.copy_(image_batch_1)\n",
        "      z_v, mu_v, logvar_v, z_a, mu_a, logvar_a, z_z, mu_z, logvar_z = encoder(X1)\n",
        "\n",
        "      all_z_v = all_z_v + list(z_v.detach().cpu().numpy())\n",
        "      all_z_a = all_z_a + list(z_a.detach().cpu().numpy())\n",
        "\n",
        "      all_v_labels = all_v_labels + list(labels[0].detach().cpu().numpy())\n",
        "      all_a_labels = all_a_labels + list(labels[1].detach().cpu().numpy())\n",
        "      all_emotion_labels = all_emotion_labels + list(emotions.detach().cpu().numpy())\n",
        "\n",
        "      sup_loss = mse_loss(z_v, labels[0].repeat(32, 1).t().cuda()) + mse_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "      \n",
        "      v_l1 = mse_loss(z_v, labels[0].repeat(32, 1).t().cuda())\n",
        "      # v_l2 = mse_loss(z_a, labels[0].repeat(32, 1).t().cuda())\n",
        "      # v_l3 = mse_loss(z_z, labels[0].repeat(32, 1).t().cuda())\n",
        "\n",
        "      # a_l1 = mse_loss(z_v, labels[1].repeat(32, 1).t().cuda())\n",
        "      a_l2 = mse_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "      # a_l3 = mse_loss(z_z, labels[1].repeat(32, 1).t().cuda())\n",
        "\n",
        "\n",
        "      sup_loss_a = mae_loss(z_v, labels[0].repeat(32, 1).t().cuda()) + mae_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "      \n",
        "      v_l_a1 = mae_loss(z_v, labels[0].repeat(32, 1).t().cuda())\n",
        "      # v_l_a2 = mae_loss(z_a, labels[0].repeat(32, 1).t().cuda())\n",
        "      # v_l_a3 = mae_loss(z_z, labels[0].repeat(32, 1).t().cuda())\n",
        "\n",
        "      # a_l_a1 = mae_loss(z_v, labels[1].repeat(32, 1).t().cuda())\n",
        "      a_l_a2 = mae_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "      # a_l_a3 = mae_loss(z_z, labels[1].repeat(32, 1).t().cuda())\n",
        "\n",
        "      # s_m1 += v_l1.item()\n",
        "      # s_m2 += v_l2.item()\n",
        "      # s_m3 += v_l3.item()\n",
        "      # s_m4 += a_l1.item()\n",
        "      # s_m5 += a_l2.item()\n",
        "      # s_m6 += a_l3.item()\n",
        "\n",
        "      # a_m1 += v_l_a1.item()\n",
        "      # a_m2 += v_l_a2.item()\n",
        "      # a_m3 += v_l_a3.item()\n",
        "      # a_m4 += a_l_a1.item()\n",
        "      # a_m5 += a_l_a2.item()\n",
        "      # a_m6 += a_l_a3.item()\n",
        "\n",
        "      s_metric += sup_loss.item()\n",
        "      s_v_m += v_l1.item()\n",
        "      s_a_m += a_l2.item()\n",
        "\n",
        "      a_metric += sup_loss_a.item()\n",
        "      a_v_m += v_l_a1.item()\n",
        "      a_a_m += a_l_a2.item()\n",
        "\n",
        "      if(iteration==1000):\n",
        "          break\n",
        "\n",
        "print(\"Combined MSE:\", s_metric/(iteration*batch_size), \"V MSE:\", s_v_m/(iteration*batch_size), \"A MSE:\", s_a_m/(iteration*batch_size))\n",
        "print(\"Combined MAE:\", a_metric/(iteration*batch_size), \"V MAE:\", a_v_m/(iteration*batch_size), \"A MAE:\", a_a_m/(iteration*batch_size))\n",
        "# print(s_m1, s_m2, s_m3, s_m4, s_m5, s_m6)\n",
        "# print(a_m1, a_m2, a_m3, a_m4, a_m5, a_m6)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Dataset...\n",
            "[('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_1.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_10.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_11.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_12.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_13.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_14.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_15.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_16.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_17.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_19.jpg', 0)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edfe822f9dbd4fd4b142b534942d5ff2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Combined MSE: 3.318751613207605 V MSE: 1.8308975290030542 A MSE: 1.4878540842045558\n",
            "Combined MAE: 0.5575481906207008 V MAE: 0.29410146798955794 A MAE: 0.2634467226311428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UbtqOiEu3dP",
        "colab_type": "text"
      },
      "source": [
        "## **LeVAsa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl0fAyUNyVcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93bc86ba-7e49-4435-86e8-cd6c8fbcd8db"
      },
      "source": [
        "class IMFDB_Reg_Encoder(nn.Module):\n",
        "\t\tdef __init__(self):\n",
        "\t\t\t\tsuper(IMFDB_Reg_Encoder, self).__init__()\n",
        "\t\t\t\tself.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.linear_mean_v = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_std_v = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_mean_a = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_std_a = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_mean_z = nn.Linear(in_features=128, out_features=32, bias=True)\n",
        "\t\t\t\tself.linear_std_z = nn.Linear(in_features=128, out_features=32, bias=True)\t\n",
        "\n",
        "\t\t\t\tself.features = nn.Linear(in_features=4608, out_features=512, bias=True)\n",
        "\t\t\t\tself.fc = nn.Linear(in_features=512, out_features=128)\n",
        "\t\t\t\tself.bn_1 = nn.BatchNorm2d(64)\n",
        "\t\t\t\tself.bn_2 = nn.BatchNorm2d(128)\n",
        "\t\t\t\tself.bn_3 = nn.BatchNorm2d(256)\n",
        "\t\t\t\tself.bn_4 = nn.BatchNorm2d(512)\n",
        "\t\t\t\tself.bn_5 = nn.BatchNorm1d(512)\n",
        "\t\t\t\tself.bn_6 = nn.BatchNorm1d(128)\n",
        "\t\t\t\tself.relu = nn.ReLU()\n",
        "\t\t\t\tself.elu = nn.ELU(0.1)\n",
        "\t\t\n",
        "\t\tdef reparameterize(self, mu, logvar):\n",
        "\t\t\t\tif is_training:\n",
        "\t\t\t\t\tstd = logvar.mul(0.5).exp_()\n",
        "\t\t\t\t\teps = torch.randn_like(std)\n",
        "\t\t\t\t\tif(torch.cuda.is_available()):\n",
        "\t\t\t\t\t\teps = eps.cuda()\n",
        "\t\t\t\t\treturn eps.mul(std).add_(mu)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\treturn mu\n",
        "\n",
        "\t\tdef forward(self, x):\n",
        "\t\t\tx = self.relu(self.bn_1(self.conv1(x)))\n",
        "\t\t\tx = self.relu(self.bn_2(self.conv2(x)))\n",
        "\t\t\tx = self.relu(self.bn_3(self.conv3(x)))\n",
        "\t\t\tx = self.relu(self.bn_4(self.conv4(x)))\n",
        "\t\t\tx = x.view(x.size(0), x.size(1)*x.size(2)*(x.size(3)))\n",
        "\t\t\t\n",
        "\t\t\tlatent_feats = self.relu(self.bn_6(self.fc(self.relu(self.bn_5(self.features(x))))))\n",
        "\t\t\tmu_v = self.linear_mean_v(latent_feats)\n",
        "\t\t\tlogvar_v = self.linear_std_v(latent_feats)\n",
        "\t\t\tmu_a = self.linear_mean_a(latent_feats)\n",
        "\t\t\tlogvar_a = self.linear_std_a(latent_feats)\n",
        "\t\t\tmu_z = self.linear_mean_z(latent_feats)\n",
        "\t\t\tlogvar_z = self.linear_std_z(latent_feats)\t \t \n",
        "\t\t\tz_v = self.reparameterize(mu_v, logvar_v)\n",
        "\t\t\tz_a = self.reparameterize(mu_a, logvar_a)\n",
        "\t\t\tz_z = self.reparameterize(mu_z, logvar_z)\t \n",
        "\n",
        "\t\t\treturn z_v, mu_v, logvar_v, z_a, mu_a, logvar_a, z_z, mu_z, logvar_z\n",
        "\n",
        "class IMFDB_Reg_Decoder(nn.Module):\n",
        "\t\tdef __init__(self):\n",
        "\t\t\t\tsuper(IMFDB_Reg_Decoder, self).__init__()\n",
        "\t\t\t\tself.inv_fc = nn.Linear(in_features=128, out_features=512, bias=True)\n",
        "\t\t\t\tself.features = nn.Linear(in_features=512, out_features=4608, bias=True)\n",
        "\t\t\t\tself.reconstruct = nn.Linear(in_features=96, out_features=128, bias=True)\n",
        "\t\t\t\tself.deconv_1 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.deconv_2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.deconv_3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, bias=True)\n",
        "\t\t\t\tself.deconv_4 = nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4, stride=2, bias=True)\n",
        "\t\t\t\tself.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "\t\t\t\tself.bn_1 = nn.BatchNorm1d(num_features=512)\n",
        "\t\t\t\tself.bn_2 = nn.BatchNorm1d(num_features=4608)\n",
        "\t\t\t\tself.bn_3 = nn.BatchNorm2d(num_features=256)\n",
        "\t\t\t\tself.bn_4 = nn.BatchNorm2d(num_features=128)\n",
        "\t\t\t\tself.bn_5 = nn.BatchNorm2d(num_features=64)\n",
        "\t\t\t\tself.bn_6 = nn.BatchNorm2d(num_features=3)\n",
        "\n",
        "\t\t\t\tself.tanh = nn.Tanh()\n",
        "\t\t\t\tself.relu =nn.ReLU()\n",
        "\n",
        "\t\tdef forward(self, z_v, z_a, z_z):\n",
        "\t\t\tconcat = torch.cat([z_v, z_a], dim=1)\n",
        "\t\t\tconcat = torch.cat([concat, z_z], dim=1)\n",
        "\t\t\tlatent = self.relu(self.bn_1(self.inv_fc(self.relu(self.reconstruct(concat)))))\n",
        "\t\t\tlatent = self.relu(self.bn_2(self.features(latent)))\n",
        "\t\t\tx = latent.view(latent.size(0), 512, 3, 3)\n",
        "\t\t\tx = self.relu(self.bn_3(self.deconv_1(x)))\n",
        "\t\t\tx = self.relu(self.bn_4(self.deconv_2(x)))\n",
        "\t\t\tx = self.relu(self.bn_5(self.deconv_3(x)))\n",
        "\t\t\tx = self.relu(self.bn_6(self.deconv_4(x)))\n",
        "\t\t\treturn x\n",
        "\n",
        "enc = IMFDB_Reg_Encoder()\n",
        "enc.cuda()\n",
        "z_v,_,_, z_a, _, _, z_z, _, _ = enc.forward(torch.randn(10, 3, 64, 64).cuda())\n",
        "print('Latents:', z_v.shape, z_a.shape, z_z.shape)\n",
        "\n",
        "dec = IMFDB_Reg_Decoder()\n",
        "dec.cuda()\n",
        "i = dec.forward(z_v, z_a, z_z)\n",
        "print('Recons:', i.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latents: torch.Size([10, 32]) torch.Size([10, 32]) torch.Size([10, 32])\n",
            "Recons: torch.Size([10, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns9VIis6u6r2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "33f48baa932749fa8c659f0e8699d56a",
            "8fbd4d05b7d04591b3089a675128ebb6",
            "0e4aca49830b4ba48c179fb7cd1b38c4",
            "78b9e36ed9104cd8972bbedcc236f8ce",
            "a74acad2586342b1ba276ce793db06d9",
            "0adffb90dc344525924559048be6e539",
            "3e32ab0d15db44e39db5974be1283748",
            "6f8970724df94dec8b988efcf8ea0cf2"
          ]
        },
        "outputId": "c61be3bc-3bfb-472c-b4fc-130e567a0640"
      },
      "source": [
        "encoder = IMFDB_Reg_Encoder()\n",
        "encoder.apply(weights_init)\n",
        "encoder.load_state_dict(torch.load('/content/drive/My Drive/LeVAsa_CODS_COMAD/experiments/Table_1_continuous/LeVAsa/reg_encoder_continuous'))\n",
        "\n",
        "decoder = IMFDB_Reg_Decoder()\n",
        "decoder.apply(weights_init)\n",
        "decoder.load_state_dict(torch.load('/content/drive/My Drive/LeVAsa_CODS_COMAD/experiments/Table_1_continuous/LeVAsa/reg_decoder_continuous'))\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "print('Loading Dataset...')\n",
        "data_dir = '/content/drive/My Drive/LeVAsa_CODS_COMAD/final_images/'\n",
        "transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
        "dset = ImageFolderWithPathsIMFDB(data_dir, transform=transform)\n",
        "print(dset.imgs[:10])\n",
        "data_object = torch.utils.data.DataLoader(dset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "X1 = torch.zeros(batch_size, 3, 64, 64)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  encoder.cuda()\n",
        "  decoder.cuda()\n",
        "  X1 = X1.cuda()\n",
        "\n",
        "s_metric = 0\n",
        "s_v_m = 0\n",
        "s_a_m = 0\n",
        "\n",
        "a_metric = 0\n",
        "a_v_m = 0\n",
        "a_a_m = 0\n",
        "\n",
        "all_z_v = []\n",
        "all_z_a = []\n",
        "all_z_z = []\n",
        "\n",
        "all_v_labels = []\n",
        "all_a_labels = []\n",
        "all_emotion_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for iteration, (data_, _, labels, emotions) in tqdm(enumerate(data_object)):\n",
        "      image_batch_1 = data_\n",
        "      X1.copy_(image_batch_1)\n",
        "      z_v, mu_v, logvar_v, z_a, mu_a, logvar_a, z_z, mu_z, logvar_z = encoder(X1)\n",
        "\n",
        "      all_z_v = all_z_v + list(z_v.detach().cpu().numpy())\n",
        "      all_z_a = all_z_a + list(z_a.detach().cpu().numpy())\n",
        "\n",
        "      all_v_labels = all_v_labels + list(labels[0].detach().cpu().numpy())\n",
        "      all_a_labels = all_a_labels + list(labels[1].detach().cpu().numpy())\n",
        "      all_emotion_labels = all_emotion_labels + list(emotions.detach().cpu().numpy())\n",
        "\n",
        "      sup_loss = mse_loss(z_v, labels[0].repeat(32, 1).t().cuda()) + mse_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "      v_l = mse_loss(z_v, labels[0].repeat(32, 1).t().cuda())\n",
        "      a_l = mse_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "\n",
        "      sup_loss_a = mae_loss(z_v, labels[0].repeat(32, 1).t().cuda()) + mae_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "      v_l_a = mae_loss(z_v, labels[0].repeat(32, 1).t().cuda())\n",
        "      a_l_a = mae_loss(z_a, labels[1].repeat(32, 1).t().cuda())\n",
        "\n",
        "      s_metric += sup_loss.item()\n",
        "      s_v_m += v_l.item()\n",
        "      s_a_m += a_l.item()\n",
        "\n",
        "      a_metric += sup_loss_a.item()\n",
        "      a_v_m += v_l_a.item()\n",
        "      a_a_m += a_l_a.item()\n",
        "\n",
        "      if(iteration==1000):\n",
        "          break\n",
        "\n",
        "print(\"Combined MSE:\", s_metric/(iteration*batch_size), \"V MSE:\", s_v_m/(iteration*batch_size), \"A MSE:\", s_a_m/(iteration*batch_size))\n",
        "print(\"Combined MAE:\", a_metric/(iteration*batch_size), \"V MAE:\", a_v_m/(iteration*batch_size), \"A MAE:\", a_a_m/(iteration*batch_size))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Dataset...\n",
            "[('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_1.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_10.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_11.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_12.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_13.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_14.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_15.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_16.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_17.jpg', 0), ('/content/drive/My Drive/AFC_Project_data/IMFDB_data/final_images/train/3Idiots_Kareena_19.jpg', 0)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33f48baa932749fa8c659f0e8699d56a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Combined MSE: 0.2080277800738765 V MSE: 0.14363004196394438 A MSE: 0.06439773810993193\n",
            "Combined MAE: 0.23486813929573 V MAE: 0.1469865681820923 A MAE: 0.08788157111363766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLhNPPdu-x34",
        "colab_type": "text"
      },
      "source": [
        "# **Table 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Krz3NRLmpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "data_dir = '/content/drive/My Drive/LeVAsa_CODS_COMAD/experiments/Table_2/'\n",
        "\n",
        "reg_z_v = pickle.load(open(data_dir+'reg_vae_z_v.pickle', 'rb'))\n",
        "reg_z_a = pickle.load(open(data_dir+'reg_vae_z_a.pickle', 'rb'))\n",
        "# reg_z_z = pickle.load(open(data_dir+'reg_vae_z_z.pickle', 'rb'))\n",
        "reg_v_labels = pickle.load(open(data_dir+'reg_vae_v_labels.pickle', 'rb'))\n",
        "reg_a_labels = pickle.load(open(data_dir+'reg_vae_a_labels.pickle', 'rb'))\n",
        "reg_emotion_labels = pickle.load(open(data_dir+'reg_vae_emotion_labels.pickle', 'rb'))\n",
        "\n",
        "vanilla_z_v = pickle.load(open(data_dir+'vanilla_vae_z_v.pickle', 'rb'))\n",
        "vanilla_z_a = pickle.load(open(data_dir+'vanilla_vae_z_a.pickle', 'rb'))\n",
        "# vanilla_z_z = pickle.load(open(data_dir+'vanilla_vae_z_z.pickle', 'rb'))\n",
        "vanilla_v_labels = pickle.load(open(data_dir+'vanilla_vae_v_labels.pickle', 'rb'))\n",
        "vanilla_a_labels = pickle.load(open(data_dir+'vanilla_vae_a_labels.pickle', 'rb'))\n",
        "vanilla_emotion_labels = pickle.load(open(data_dir+'vanilla_vae_emotion_labels.pickle', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H43hCGHK-1cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gridsearch(X_train, y_train):\n",
        "        tuned_parameters = {\n",
        "            'hidden_layer_sizes': [(10,), (50,), (90,), (100,)],\n",
        "            'activation': ['relu'],\n",
        "            'solver': ['sgd', 'adam'],\n",
        "        }\n",
        "        clf = GridSearchCV(\n",
        "            MLPRegressor(random_state=1), tuned_parameters, scoring=\"neg_mean_squared_error\"\n",
        "        )\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        y_true, y_pred = y_test, clf.predict(X_test)\n",
        "        print(mean_squared_error(y_true, y_pred), mean_absolute_error(y_true, y_pred), explained_variance_score(y_test, clf.predict(X_test)), r2_score(y_test, clf.predict(X_test)))#, clf.best_params_, clf.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsWDpLKS_zF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "90cd0fc8-18d5-4543-fc85-06597442569b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "preprocessing.scale(vanilla_z_v)\n",
        "preprocessing.scale(vanilla_z_a)\n",
        "preprocessing.scale(reg_z_v)\n",
        "preprocessing.scale(reg_z_a)\n",
        "\n",
        "################# Vanilla Valence #########################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_v, vanilla_v_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "gridsearch(vanilla_z_v, vanilla_v_labels)\n",
        "\n",
        "# ################# Vanilla Arousal #########################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_a, vanilla_a_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "gridsearch(vanilla_z_a, vanilla_a_labels)\n",
        "\n",
        "# ################# Reg Valence #########################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_v, reg_v_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "gridsearch(reg_z_v, reg_v_labels)\n",
        "\n",
        "# ################# Reg Arousal #########################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_a, reg_a_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "gridsearch(reg_z_a, reg_a_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.25466069450212503 0.4222959327882577 -0.0034137875637900716 -0.0035008957884801184\n",
            "0.08920973559293859 0.24493112481672333 -0.008358290286107461 -0.011615461278852157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.24314636527760874 0.40575350959048934 0.04747090316288405 0.04737829952225481\n",
            "0.07499406204659798 0.2278122769054959 0.09000087045006844 0.07956007134538179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzbHmQ6o-f7r",
        "colab_type": "text"
      },
      "source": [
        "# **Table 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q32_wVRANsoT",
        "colab_type": "text"
      },
      "source": [
        "## **Continuous**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO4-Bo9t1KPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "851a72c4-5511-4115-9c4f-7323341f883d"
      },
      "source": [
        "import pickle\n",
        "\n",
        "data_dir = '/content/drive/My Drive/LeVAsa_CODS_COMAD/experiments/Table_3_continuous/'\n",
        "\n",
        "reg_z_v = pickle.load(open(data_dir+'reg_vae_z_v.pickle', 'rb'))\n",
        "reg_z_a = pickle.load(open(data_dir+'reg_vae_z_a.pickle', 'rb'))\n",
        "reg_z_z = pickle.load(open(data_dir+'reg_vae_z_z.pickle', 'rb'))\n",
        "reg_v_labels = pickle.load(open(data_dir+'reg_vae_v_labels.pickle', 'rb'))\n",
        "reg_a_labels = pickle.load(open(data_dir+'reg_vae_a_labels.pickle', 'rb'))\n",
        "reg_emotion_labels = pickle.load(open(data_dir+'reg_vae_emotion_labels.pickle', 'rb'))\n",
        "\n",
        "vanilla_z_v = pickle.load(open(data_dir+'vanilla_vae_z_v.pickle', 'rb'))\n",
        "vanilla_z_a = pickle.load(open(data_dir+'vanilla_vae_z_a.pickle', 'rb'))\n",
        "vanilla_z_z = pickle.load(open(data_dir+'vanilla_vae_z_z.pickle', 'rb'))\n",
        "vanilla_v_labels = pickle.load(open(data_dir+'vanilla_vae_v_labels.pickle', 'rb'))\n",
        "vanilla_a_labels = pickle.load(open(data_dir+'vanilla_vae_a_labels.pickle', 'rb'))\n",
        "vanilla_emotion_labels = pickle.load(open(data_dir+'vanilla_vae_emotion_labels.pickle', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2002 2002 2002 2002 2002\n",
            "2002 2002 2002 2002 2002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWL39g0d4fvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "64156eca-38a5-4df3-e9ea-80d998e07a2e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "preprocessing.scale(vanilla_z_v)\n",
        "preprocessing.scale(vanilla_z_a)\n",
        "preprocessing.scale(vanilla_z_z)\n",
        "preprocessing.scale(reg_z_v)\n",
        "preprocessing.scale(reg_z_a)\n",
        "preprocessing.scale(reg_z_z)\n",
        "\n",
        "###################### Vanilla VAE results ################################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_v, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Vanilla V MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_a, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Vanilla A MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_z, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Vanilla Z MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "###################### LeVAsa results ################################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_v, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Reg V MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_a, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Reg A MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_z, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Reg Z MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "###################### Concatenated chunk results ################################\n",
        "\n",
        "zconcat = np.concatenate((vanilla_z_v, vanilla_z_a), axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(zconcat, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 2 Van MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "zconcat = np.concatenate((reg_z_v, reg_z_a), axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(zconcat, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 2 Reg MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "concat_van = np.concatenate((vanilla_z_v, vanilla_z_a, vanilla_z_z), axis=1)\n",
        "concat_reg = np.concatenate((reg_z_v, reg_z_a, reg_z_z), axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(concat_van, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 3 Van MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(concat_reg, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 3 Reg MLP: '+str(accuracy_score(y_test, preds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vanilla V MLP: 0.2911813643926789\n",
            "Vanilla A MLP: 0.3227953410981697\n",
            "Vanilla Z MLP: 0.3211314475873544\n",
            "Reg V MLP: 0.3627287853577371\n",
            "Reg A MLP: 0.3560732113144759\n",
            "Reg Z MLP: 0.3610648918469218\n",
            "Concat 2 Van MLP: 0.3277870216306156\n",
            "Concat 2 Reg MLP: 0.3793677204658902\n",
            "Concat 3 Van MLP: 0.2911813643926789\n",
            "Concat 3 Reg MLP: 0.33444259567387685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhQj27f1NzyL",
        "colab_type": "text"
      },
      "source": [
        "## **Discrete**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J6qV14f8B9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d3b6116-964b-4bb4-fd8d-04c3d392a3c2"
      },
      "source": [
        "import pickle\n",
        "\n",
        "data_dir = '/content/drive/My Drive/LeVAsa_CODS_COMAD/experiments/Table_3_discrete/'\n",
        "\n",
        "reg_z_v = pickle.load(open(data_dir+'reg_vae_z_v_discrete.pickle', 'rb'))\n",
        "reg_z_a = pickle.load(open(data_dir+'reg_vae_z_a_discrete.pickle', 'rb'))\n",
        "reg_z_z = pickle.load(open(data_dir+'reg_vae_z_z_discrete.pickle', 'rb'))\n",
        "reg_emotion_labels = pickle.load(open(data_dir+'reg_vae_emotion_labels_discrete.pickle', 'rb'))\n",
        "\n",
        "vanilla_z_v = pickle.load(open(data_dir+'vanilla_vae_z_v.pickle', 'rb'))\n",
        "vanilla_z_a = pickle.load(open(data_dir+'vanilla_vae_z_a.pickle', 'rb'))\n",
        "vanilla_z_z = pickle.load(open(data_dir+'vanilla_vae_z_z.pickle', 'rb'))\n",
        "vanilla_emotion_labels = pickle.load(open(data_dir+'vanilla_vae_emotion_labels.pickle', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2002 2002 2002 2002\n",
            "2002 2002 2002 2002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ghD4ccG9m81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "559ca2aa-0694-4f4d-bc0b-bc60fce2f076"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "preprocessing.scale(vanilla_z_v)\n",
        "preprocessing.scale(vanilla_z_a)\n",
        "preprocessing.scale(vanilla_z_z)\n",
        "preprocessing.scale(reg_z_v)\n",
        "preprocessing.scale(reg_z_a)\n",
        "preprocessing.scale(reg_z_z)\n",
        "\n",
        "###################### Vanilla VAE results ################################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_v, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Vanilla V MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_a, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Vanilla A MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vanilla_z_z, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Vanilla Z MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "###################### LeVAsa VAE results ################################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_v, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Reg V MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_a, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Reg A MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reg_z_z, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Reg Z MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "###################### Concatenated chunk results ################################\n",
        "\n",
        "zconcat = np.concatenate((vanilla_z_v, vanilla_z_a), axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(zconcat, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 2 Van MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "zconcat = np.concatenate((reg_z_v, reg_z_a), axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(zconcat, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 2 Reg MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "concat_van = np.concatenate((vanilla_z_v, vanilla_z_a, vanilla_z_z), axis=1)\n",
        "concat_reg = np.concatenate((reg_z_v, reg_z_a, reg_z_z), axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(concat_van, vanilla_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 3 Van MLP: '+str(accuracy_score(y_test, preds)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(concat_reg, reg_emotion_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Concat 3 Reg MLP: '+str(accuracy_score(y_test, preds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vanilla V MLP: 0.30615640599001664\n",
            "Vanilla A MLP: 0.27454242928452577\n",
            "Vanilla Z MLP: 0.24126455906821964\n",
            "Reg V MLP: 0.3594009983361065\n",
            "Reg A MLP: 0.2995008319467554\n",
            "Reg Z MLP: 0.2928452579034942\n",
            "Concat 2 Van MLP: 0.24958402662229617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Concat 2 Reg MLP: 0.33444259567387685\n",
            "Concat 3 Van MLP: 0.2628951747088186\n",
            "Concat 3 Reg MLP: 0.2928452579034942\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}